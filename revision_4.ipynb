{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full revision analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of work to be performed:\n",
    "1. Supplementary figure showing incorrect inform tumor segmentation and NKT cells \n",
    "2. Supplementary figure with zoom-in images of individual cells from inForm and TME-Analyzer in an image with high disagreement \n",
    "3. Incorporation of DeepCell into TME-Analyzer \n",
    "4. Reorganize the MonteCarlo trials \n",
    "5. Supplementary table 6 with full ranking of parameters and discovery/validation p values if top n parameters were used instead. \n",
    "6. Generate forest plot for 4E \n",
    "7. Build classifier based on train-test split of discovery cohort. Try 16-47, 32-31, 47-16 splits. \n",
    "8. ? It is significant amount of work, but since both reviewers mention is, I can train a random forest on the original dataset and report it ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reorganize the MonteCarlo trials \n",
    "We now provide a zip folder consisting of a \n",
    "\n",
    "4.1 .csv file listing the classifier parameters, \n",
    "\n",
    "4.2 a .txt file listing the patient split to test-train groups and \n",
    "\n",
    "4.3 the classifier performance, and \n",
    "\n",
    "4.4 a .png file plotting the Kaplan-Meier curves of patient groups; per classifier (a total of 3000 files, 70Mb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 4.2 & 4.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "Classifier_folder = \"E:/Desktop_backup_20231031/Desktop/TME-Analyzer_the_manuscript/all_ML_approaches/v2/trials_20201202/first_1000/\"\n",
    "Classifier_folder = 'E:/Moved from E/TME-Analyzer_the_manuscript/20211129_TME-Analyzer/ML/individual classifiers/'\n",
    "output_folder = \"E:/TME-Analyzer-large-files-from-desktop-folder/20231207_revision_files/Task4/\"\n",
    "patient_lookup = pd.read_excel(\"E:/Moved from E/TME-Analyzer_the_manuscript/20211129_TME-Analyzer/data_analysis/reproduction_of_old_analysis/20230712/discovery_data.xlsx\", engine='openpyxl')\n",
    "patient_lookup = patient_lookup.set_index(patient_lookup.keys()[0]).iloc[:,0]\n",
    "# print(patient_lookup)\n",
    "px_size = 0.4999\n",
    "classifier_files = np.sort([i for i in os.listdir(Classifier_folder) if (i[-4:] == '.txt') & ('classifier_2022' in i)])\n",
    "n_i = 0\n",
    "for n_i in range(1000):\n",
    "    file_name = Classifier_folder + classifier_files[n_i]\n",
    "    with open(file_name,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(output_folder + 'classifier_' + f'{n_i+1:04d}' + '.txt','w') as f:\n",
    "        for line in lines:\n",
    "            for i in patient_lookup.index:\n",
    "                # print(i)\n",
    "                # print(line,type(line))\n",
    "                if str(i) in line:\n",
    "                    line = line.replace(str(i),str(patient_lookup.loc[i]))\n",
    "            # print(line)\n",
    "            f.write(line)\n",
    "        # print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_i in range(1000):\n",
    "# n_i = 0\n",
    "    file_name = Classifier_folder + classifier_files[n_i].replace('.txt','.xls')\n",
    "\n",
    "    px_size_dora = 0.4999\n",
    "    classifier_frame = pd.read_csv(file_name,sep='\\t')\n",
    "\n",
    "    classifier_frame_new = pd.DataFrame(classifier_frame[['mean (good prognosis)', 'mean (bad prognosis)','p-value','used for classifier?']])\n",
    "    classifier_frame_new.index = classifier_frame['Unnamed: 0']#,columns = ['mean (good prognosis)', 'mean (bad prognosis)'])\n",
    "    px_size_cols = ['mean (good prognosis)', 'mean (bad prognosis)']\n",
    "    for i in classifier_frame_new.index:\n",
    "        if 'area' in i:\n",
    "            classifier_frame_new.loc[i,px_size_cols] = classifier_frame_new.loc[i,px_size_cols]*px_size_dora*px_size_dora\n",
    "        elif 'density' in i:\n",
    "            classifier_frame_new.loc[i,px_size_cols] = classifier_frame_new.loc[i,px_size_cols]/px_size_dora/px_size_dora\n",
    "\n",
    "    new_index = []\n",
    "    for i in classifier_frame_new.index:\n",
    "        if 'found' in i:\n",
    "            new_index.append(i[:i.find('found')-1])\n",
    "        else:\n",
    "            new_index.append(i[:i[::-1].find('ni')*-1-3])\n",
    "    classifier_frame_new.index = new_index\n",
    "\n",
    "    classifier_frame_new.to_excel(output_folder + 'classifier_' + f'{n_i+1:04d}' + '.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_i in range(1000):\n",
    "    shutil.copy(Classifier_folder + classifier_files[n_i].replace('.txt','_os.png'), output_folder + 'classifier_' + f'{n_i+1:04d}' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
